{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitbaseconda418bb85f4e7240b4aae9dd6159ea9afa",
   "display_name": "Python 3.6.10 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFromDataSet(ds):\n",
    "    csv_x = pandas.read_csv(f'./data/{ds}_x.csv',header=0,index_col=0)\n",
    "    csv_y = pandas.read_csv(f'./data/{ds}_y.csv',header=0,index_col=0)\n",
    "    return csv_x.T.values, csv_y['x'].values\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varianceFilter(X_train,X_test,desiredFeature):\n",
    "    result_X_train=numpy.zeros((X_train.shape[0], 0))\n",
    "    result_X_test =numpy.zeros((X_test.shape[0], 0))\n",
    "    # fill index\n",
    "    vars=numpy.var(X_train,axis=0)\n",
    "    var_test=numpy.var(X_test,axis=0)\n",
    "    # append index\n",
    "    VARS=[]\n",
    "    for i in range(len(vars)):\n",
    "        VARS.append((vars[i],i))\n",
    "    VARS.sort()\n",
    "    for _, index in VARS[len(VARS):len(VARS)-desiredFeature-1:-1]:\n",
    "        result_X_train=numpy.append(result_X_train, X_train[:,index].reshape(X_train.shape[0], 1), axis=1)\n",
    "        result_X_test =numpy.append(result_X_test , X_test [:,index].reshape(X_test.shape[0], 1), axis=1)\n",
    "    return result_X_train, result_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptronCheat(X_train,X_test,sqrSize,Y_train):\n",
    "    import sklearn\n",
    "    from sklearn.linear_model import Perceptron\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    clf = Perceptron(tol=0, max_iter=2000)\n",
    "    clf.fit (X_train, Y_train)\n",
    "    coef = clf.coef_[0]\n",
    "    tmp = []\n",
    "    i = 0\n",
    "    for a in coef: \n",
    "        tmp.append ((a, i))\n",
    "        i+=1\n",
    "    tmp.sort ()\n",
    "    totalSize = sqrSize\n",
    "    head = totalSize // 2\n",
    "    tail = totalSize - head\n",
    "    selected = [index for (value, index) in tmp[:head]]\n",
    "    selected.extend ([index for (value, index) in tmp[len(tmp)-1:len(tmp)-tail-1:-1]])\n",
    "\n",
    "    result_X_train=numpy.zeros((X_train.shape[0], 0))\n",
    "    result_X_test =numpy.zeros((X_test.shape[0], 0))\n",
    "    result_X_train=numpy.append(result_X_train, X_train[:,selected].reshape(X_train.shape[0], len (selected)), axis=1)\n",
    "    result_X_test =numpy.append(result_X_test , X_test [:,selected].reshape(X_test.shape[0],  len (selected)), axis=1)\n",
    "    return result_X_train, result_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anovaFValue(X_train, X_test, desiredFeature, Y_train):\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.feature_selection import f_classif\n",
    "    fvalue_selector = SelectKBest(f_classif, k=desiredFeature)\n",
    "    X_train=fvalue_selector.fit_transform(X_train, Y_train)\n",
    "    X_test=fvalue_selector.transform(X_test)\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\"\"\"\n",
    "fcbf.py\n",
    "Created by Prashant Shiralkar on 2015-02-06.\n",
    "Fast Correlation-Based Filter (FCBF) algorithm as described in \n",
    "Feature Selection for High-Dimensional Data: A Fast Correlation-Based\n",
    "Filter Solution. Yu & Liu (ICML 2003)\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "def entropy(vec, base=2):\n",
    "\t\" Returns the empirical entropy H(X) in the input vector.\"\n",
    "\t_, vec = np.unique(vec, return_counts=True)\n",
    "\tprob_vec = np.array(vec/float(sum(vec)))\n",
    "\tif base == 2:\n",
    "\t\tlogfn = np.log2\n",
    "\telif base == 10:\n",
    "\t\tlogfn = np.log10\n",
    "\telse:\n",
    "\t\tlogfn = np.log\n",
    "\treturn prob_vec.dot(-logfn(prob_vec))\n",
    "\n",
    "def conditional_entropy(x, y):\n",
    "\t\"Returns H(X|Y).\"\n",
    "\tuy, uyc = np.unique(y, return_counts=True)\n",
    "\tprob_uyc = uyc/float(sum(uyc))\n",
    "\tcond_entropy_x = np.array([entropy(x[y == v]) for v in uy])\n",
    "\treturn prob_uyc.dot(cond_entropy_x)\n",
    "\t\n",
    "def mutual_information(x, y):\n",
    "\t\" Returns the information gain/mutual information [H(X)-H(X|Y)] between two random vars x & y.\"\n",
    "\treturn entropy(x) - conditional_entropy(x, y)\n",
    "\n",
    "def symmetrical_uncertainty(x, y):\n",
    "\t\" Returns 'symmetrical uncertainty' (SU) - a symmetric mutual information measure.\"\n",
    "\treturn 2.0*mutual_information(x, y)/(entropy(x) + entropy(y))\n",
    "\n",
    "def getFirstElement(d):\n",
    "\t\"\"\"\n",
    "\tReturns tuple corresponding to first 'unconsidered' feature\n",
    "\t\n",
    "\tParameters:\n",
    "\t----------\n",
    "\td : ndarray\n",
    "\t\tA 2-d array with SU, original feature index and flag as columns.\n",
    "\t\n",
    "\tReturns:\n",
    "\t-------\n",
    "\ta, b, c : tuple\n",
    "\t\ta - SU value, b - original feature index, c - index of next 'unconsidered' feature\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tt = np.where(d[:,2]>0)[0]\n",
    "\tif len(t):\n",
    "\t\treturn d[t[0],0], d[t[0],1], t[0]\n",
    "\treturn None, None, None\n",
    "\n",
    "def getNextElement(d, idx):\n",
    "\t\"\"\"\n",
    "\tReturns tuple corresponding to the next 'unconsidered' feature.\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\td : ndarray\n",
    "\t\tA 2-d array with SU, original feature index and flag as columns.\n",
    "\tidx : int\n",
    "\t\tRepresents original index of a feature whose next element is required.\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\ta, b, c : tuple\n",
    "\t\ta - SU value, b - original feature index, c - index of next 'unconsidered' feature\n",
    "\t\"\"\"\n",
    "\tt = np.where(d[:,2]>0)[0]\n",
    "\tt = t[t > idx]\n",
    "\tif len(t):\n",
    "\t\treturn d[t[0],0], d[t[0],1], t[0]\n",
    "\treturn None, None, None\n",
    "\t\n",
    "def removeElement(d, idx):\n",
    "\t\"\"\"\n",
    "\tReturns data with requested feature removed.\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\td : ndarray\n",
    "\t\tA 2-d array with SU, original feature index and flag as columns.\n",
    "\tidx : int\n",
    "\t\tRepresents original index of a feature which needs to be removed.\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\td : ndarray\n",
    "\t\tSame as input, except with specific feature removed.\n",
    "\t\"\"\"\n",
    "\td[idx,2] = 0\n",
    "\treturn d\n",
    "\n",
    "def c_correlation(X, y):\n",
    "\t\"\"\"\n",
    "\tReturns SU values between each feature and class.\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tX : 2-D ndarray\n",
    "\t\tFeature matrix.\n",
    "\ty : ndarray\n",
    "\t\tClass label vector\n",
    "\t\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tsu : ndarray\n",
    "\t\tSymmetric Uncertainty (SU) values for each feature.\n",
    "\t\"\"\"\n",
    "\tsu = np.zeros(X.shape[1])\n",
    "\tfor i in np.arange(X.shape[1]):\n",
    "\t\tsu[i] = symmetrical_uncertainty(X[:,i], y)\n",
    "\treturn su\n",
    "\n",
    "def fcbf(X, y, thresh, X_train, X_test):\n",
    "\t\"\"\"\n",
    "\tPerform Fast Correlation-Based Filter solution (FCBF).\n",
    "\t\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tX : 2-D ndarray\n",
    "\t\tFeature matrix\n",
    "\ty : ndarray\n",
    "\t\tClass label vector\n",
    "\tthresh : float\n",
    "\t\tA value in [0,1) used as threshold for selecting 'relevant' features. \n",
    "\t\tA negative value suggest the use of minimum SU[i,c] value as threshold.\n",
    "\t\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tsbest : 2-D ndarray\n",
    "\t\tAn array containing SU[i,c] values and feature index i.\n",
    "\t\"\"\"\n",
    "\tn = X.shape[1]\n",
    "\tslist = np.zeros((n, 3))\n",
    "\tslist[:, -1] = 1\n",
    "\n",
    "\t# identify relevant features\n",
    "\tslist[:,0] = c_correlation(X, y) # compute 'C-correlation'\n",
    "\tidx = slist[:,0].argsort()[::-1]\n",
    "\tslist = slist[idx, ]\n",
    "\tslist[:,1] = idx\n",
    "\tif thresh < 0:\n",
    "\t\tthresh = np.median(slist[-1,0])\n",
    "\t\tprint (\"Using minimum SU value as default threshold: {0}\".format(thresh))\n",
    "\telif thresh >= 1 or thresh > max(slist[:,0]):\n",
    "\t\tprint (\"No relevant features selected for given threshold.\")\n",
    "\t\tprint (\"Please lower the threshold and try again.\")\n",
    "\t\texit()\n",
    "\t\t\n",
    "\tslist = slist[slist[:,0]>thresh,:] # desc. ordered per SU[i,c]\n",
    "\t\n",
    "\t# identify redundant features among the relevant ones\n",
    "\tcache = {}\n",
    "\tm = len(slist)\n",
    "\tp_su, p, p_idx = getFirstElement(slist)\n",
    "\tfor i in range(m):\n",
    "\t\tp = int(p)\n",
    "\t\tq_su, q, q_idx = getNextElement(slist, p_idx)\n",
    "\t\tif q:\n",
    "\t\t\twhile q:\n",
    "\t\t\t\tq = int(q)\n",
    "\t\t\t\tif (p, q) in cache:\n",
    "\t\t\t\t\tpq_su = cache[(p,q)]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tpq_su = symmetrical_uncertainty(X[:,p], X[:,q])\n",
    "\t\t\t\t\tcache[(p,q)] = pq_su\n",
    "\n",
    "\t\t\t\tif pq_su >= q_su:\n",
    "\t\t\t\t\tslist = removeElement(slist, q_idx)\n",
    "\t\t\t\tq_su, q, q_idx = getNextElement(slist, q_idx)\n",
    "\t\t\t\t\n",
    "\t\tp_su, p, p_idx = getNextElement(slist, p_idx)\n",
    "\t\tif not p_idx:\n",
    "\t\t\tbreak\n",
    "\tsbest = slist[slist[:,2]>0, :2]\n",
    "\tselected = [int(_[1]) for _ in sbest]\n",
    "\treturn X_train[:,selected], X_test[:, selected]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rigde(X_train, X_test, desiredFeature, Y_train, Y_test):\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    transformer = SelectFromModel(estimator=LogisticRegression(C=1, penalty='l2'), threshold=-numpy.inf, max_features=desiredFeature).fit(X_train, Y_train)\n",
    "    X_train = transformer.transform(X_train)\n",
    "    X_test  = transformer.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureAggo(X_train, X_test, desiredFeature, Y_train, Y_test):\n",
    "    from sklearn.cluster import FeatureAgglomeration\n",
    "    transformer = FeatureAgglomeration(n_clusters=desiredFeature)\n",
    "    X_train = transformer.fit_transform(X_train)\n",
    "    X_test = transformer.fit_transform(X_test)\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def madFilter(X_train, X_test, firstStageFeature, Y_train, Y_test):\n",
    "    X_train_stage1, X_test_stage1 = varianceFilter(X_train, X_test, firstStageFeature)\n",
    "    # binning afterward\n",
    "    from sklearn.preprocessing import KBinsDiscretizer\n",
    "    KBin = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform') # Quantile\n",
    "    KBin.fit(X_train_stage1)\n",
    "    X_train_stage2 = KBin.transform(X_train_stage1)\n",
    "    X_test_stage2 = KBin.transform(X_test_stage1)\n",
    "    # run feature selection\n",
    "    X_train_stage3, X_test_stage3 = fcbf(X_train_stage2, Y_train, 0.001, X_train, X_test)\n",
    "    return X_train_stage3, X_test_stage3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = importFromDataSet('wt2dgene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(96, 1415610) (96,)\n[0.27180253 0.0392678  0.00092365 ... 0.         0.         0.        ]\n"
    }
   ],
   "source": [
    "print(X.shape, Y.shape)\n",
    "X_mean = numpy.mean(X, axis=0)\n",
    "print(X_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = X.shape[0]\n",
    "sample_taken = sample_count * 9 // 10\n",
    "X_train, X_test = X[:sample_taken,:], X[sample_taken:sample_count,:]\n",
    "Y_train, Y_test = Y[:sample_taken], Y[sample_taken:sample_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_X_train, stage_X_test = madFilter(X_train, X_test, 4096, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1.89448e-05 1.33295e-05 1.17408e-05 ... 5.74945e-05 6.65978e-06\n  2.33907e-05]\n [9.25497e-06 8.99514e-06 5.77391e-06 ... 3.20219e-05 0.00000e+00\n  2.80234e-06]\n [2.25646e-05 8.35721e-06 2.38212e-05 ... 5.15908e-05 6.40331e-06\n  1.77478e-05]\n ...\n [3.02362e-05 2.49585e-05 3.46357e-05 ... 1.91481e-05 1.49868e-05\n  3.20443e-05]\n [2.16905e-05 1.34104e-05 2.15808e-05 ... 1.85749e-05 3.56302e-07\n  2.59663e-05]\n [5.56239e-06 1.68132e-05 4.15281e-05 ... 7.69070e-06 5.46970e-07\n  7.70159e-05]]\n"
    }
   ],
   "source": [
    "print(stage_X_train)"
   ]
  }
 ]
}